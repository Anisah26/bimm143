---
title: "Class08: Machine Learning (Mini Project)"
author: "Raidah Anisah Huda A16124317"
format: pdf
editor: visual
---

# Breast Cancer Project

Today we are going to explore some data from the University of Wisconsin Cancer Center on Breast biopsy data.

```{r}
wisc.data<-read.csv("WisconsinCancer.csv", row.names=1)
head(wisc.data)

```

> Q1. How many patient samples are in this dataset?

```{r}
nrow(wisc.data)
```

There are `r nrow(wisc.data)` patients in this dataset.

> Q2. How many cancer(M) and non cancer (B) samples are there?

```{r}
table(wisc.data$diagnosis)
```

There are 357 benign and 212 malignant cells.

Save the diagnosis for later use as a reference to compare how well we do with PCA etc.

```{r}
diagnosis <- as.factor(wisc.data$diagnosis)
#diagnosis
```

Now exclude the diagnosis column from the data.

```{r}
wisc <- wisc.data[,-1]
```

> Q3. How many 'dimensions', 'variables', 'columns' are there in this dataset?

```{r}
ncol(wisc)
```

We have 30 variables in this dataset.

# Performing Principal Component Analysis(PCA)

To perform PCA in R, we can use the `prcomp()` function. It takes as input a numerical dataset and optional `scale=FALSE/TRUE` argument.

We generally always want to set `scale=TRUE` but let's make sure by checking if the mean and standard deviation values are different across these 30 columns.

```{r}
# Check column means and standard deviations
round(colMeans(wisc))
round(apply(wisc,2,sd))
```

```{r}
pca <- prcomp(wisc,scale=TRUE)
summary(pca)
```

```{r}
attributes(pca)
```

```{r}
plot(pca$x[,1], pca$x[,2], col=diagnosis)
```

```{r}
library(ggplot2)

x<- as.data.frame(pca$x)

ggplot(x)+
  aes(PC1, PC2, col=diagnosis)+
  geom_point()
```

> Q4. How much varience is captured in the top 3 PCs?

They capture 76.2% of the total variance.

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr\$rotation\[,1\]) for the feature concave.points_mean? This tells us how much this original feature contributes to the first PC

```{r}
pca$rotation["concave.points_mean",1]
```

```{r}
attributes(pca)
```

# Combining PCA results with clustering

We can use our new PCA variables (i.e. the scores along the PCs contained in the `pca$x`) as input for other methods such as clustering.

```{r}
#Hclust needs a distance matrix as input
d <- dist(pca$x[,1:3])

hc <- hclust(d, method="ward.D2")
plot(hc)
```

To get our cluster membership vector we can use the `cutree()` function and specify a heigt(`h`) or number of groups(`k`).

```{r}
grps <- cutree(hc, h=80)
table(grps)
```

I want to find out how many diagnosis "M" and "B" are in each grp?

```{r}
table(diagnosis,grps)
```

In group 1, there are 24 benign and 179 malignant cases. In group 2, 333 cases were benign and 33 were malignant.

We can also plot our results using our clustering vector `grps`.

```{r}
plot(pca$x[,1], pca$x[,2], col=grps)

```

```{r}
ggplot(x)+
  aes(PC1, PC2)+
  geom_point(col=grps)
```

> Q15. What is the sensitivity and specificity of our current results?

```{r}
table(wisc.data$diagnosis)
table(diagnosis,grps)
```

Sensitivity= TP/(TP+FN)

```{r}
Sen<-179/(179+33)
Sen

```

Specificity = TN/(TN+FN)

```{r}
Spec <- 333/(333+33)
Spec
```

The specificity is 90.98% and the sensitivity is 84.43%.

# Prediction

```{r}

url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(pca, newdata=new)
npc

```

```{r}
plot(pca$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```
